{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import re"
      ],
      "metadata": {
        "id": "PH_mcB21EoxE"
      },
      "execution_count": 358,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 359,
      "metadata": {
        "id": "bJQINrKnDqju"
      },
      "outputs": [],
      "source": [
        "with open('train_data.txt', 'r', encoding='utf-8') as f:\n",
        "    text = f.read()\n",
        "    text = text.replace('\\ufeff', '') # убираем первый невидимый символ\n",
        "    text = re.sub(r'[^А-я ]', '', text) # убираем все недопустимые символы"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "SubXLsi5ErEN",
        "outputId": "473f9e83-c20b-4fdb-d247-ae5a839787d0"
      },
      "execution_count": 360,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Вы  лучший ответ на проблемы которые возникли в понедельникДумайте позитивно и верьте в свою способность достигать отличных результатовЕсли вы смогли в понедельник подняться с постели значит вы супер герой'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 360
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fyD7g4glKVps",
        "outputId": "bbfa5240-f3c8-4f8c-f8b2-2b2060644627"
      },
      "execution_count": 361,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "205"
            ]
          },
          "metadata": {},
          "execution_count": 361
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_characters = 34 #33 буквы + пробел"
      ],
      "metadata": {
        "id": "IJD76YJ4E6z0"
      },
      "execution_count": 362,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.preprocessing.text import Tokenizer"
      ],
      "metadata": {
        "id": "DgiJrgsiIK_x"
      },
      "execution_count": 363,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(num_words=num_characters, char_level=True)"
      ],
      "metadata": {
        "id": "appv1wfpIJvH"
      },
      "execution_count": 364,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.fit_on_texts(text)"
      ],
      "metadata": {
        "id": "N1yoi7pGId-n"
      },
      "execution_count": 365,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJmXPaQbIf-I",
        "outputId": "66df18a0-9503-47f6-fbaa-cd31910b11f6"
      },
      "execution_count": 366,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{' ': 1, 'о': 2, 'т': 3, 'е': 4, 'и': 5, 'в': 6, 'н': 7, 'с': 8, 'л': 9, 'п': 10, 'ь': 11, 'ы': 12, 'р': 13, 'а': 14, 'д': 15, 'у': 16, 'к': 17, 'з': 18, 'ч': 19, 'й': 20, 'м': 21, 'г': 22, 'б': 23, 'я': 24, 'ш': 25, 'ю': 26, 'х': 27}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inp_chars = 6 #\n",
        "data = tokenizer.texts_to_matrix(text)"
      ],
      "metadata": {
        "id": "1wWs_206JRu-"
      },
      "execution_count": 367,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yqy7uBYCJTYV",
        "outputId": "aab4a3e5-79d9-48a7-c973-b646e154aa45"
      },
      "execution_count": 368,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 368
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n = data.shape[0]-inp_chars\n",
        "n  #размер обучающего множества"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HnWQb42jKAd1",
        "outputId": "3d2012a8-1515-4397-be8e-2c72f9173082"
      },
      "execution_count": 369,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "199"
            ]
          },
          "metadata": {},
          "execution_count": 369
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "kvZ-iB9LKwgc"
      },
      "execution_count": 370,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array([data[i:i+inp_chars, :] for i in range(n)])\n",
        "Y = data[inp_chars:] #предсказание следующего символа"
      ],
      "metadata": {
        "id": "_nG7M5RIKsfs"
      },
      "execution_count": 371,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z20DCMmSK3tj",
        "outputId": "f321d108-b19e-44e6-d24b-6fe662bae2b6"
      },
      "execution_count": 372,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "199"
            ]
          },
          "metadata": {},
          "execution_count": 372
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0NrELysIK5fL",
        "outputId": "1fd9b195-0170-4ca7-b361-296d7fa8804f"
      },
      "execution_count": 373,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 373
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XbsyrcEGK7G7",
        "outputId": "2158ace0-31af-4726-be89-cc5e7f5cd076"
      },
      "execution_count": 374,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 374
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import *\n",
        "from keras.models import Sequential"
      ],
      "metadata": {
        "id": "lIP7yhRzLZsr"
      },
      "execution_count": 375,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Input((inp_chars, num_characters)))\n",
        "model.add(SimpleRNN(500, activation='tanh'))\n",
        "model.add(Dense(num_characters, activation='softmax'))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwyYcqGiLXPE",
        "outputId": "999dba14-d6dd-4983-8fa5-c74c3d86e650"
      },
      "execution_count": 376,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " simple_rnn_14 (SimpleRNN)   (None, 500)               267500    \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 34)                17034     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 284534 (1.09 MB)\n",
            "Trainable params: 284534 (1.09 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
        "history = model.fit(X, Y, batch_size=32, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3-y2cQiMGLK",
        "outputId": "342e3b51-01cf-44bc-dc88-4ece3d285de6"
      },
      "execution_count": 377,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "7/7 [==============================] - 1s 15ms/step - loss: 3.3770 - accuracy: 0.1156\n",
            "Epoch 2/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 2.4515 - accuracy: 0.2814\n",
            "Epoch 3/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 1.9580 - accuracy: 0.4523\n",
            "Epoch 4/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 1.5500 - accuracy: 0.5025\n",
            "Epoch 5/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 1.2540 - accuracy: 0.6382\n",
            "Epoch 6/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 1.0186 - accuracy: 0.7236\n",
            "Epoch 7/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.9212 - accuracy: 0.7387\n",
            "Epoch 8/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.7894 - accuracy: 0.7839\n",
            "Epoch 9/100\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.6400 - accuracy: 0.8392\n",
            "Epoch 10/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.6007 - accuracy: 0.8241\n",
            "Epoch 11/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.5305 - accuracy: 0.8894\n",
            "Epoch 12/100\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.4233 - accuracy: 0.9146\n",
            "Epoch 13/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.3821 - accuracy: 0.9347\n",
            "Epoch 14/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.3450 - accuracy: 0.9146\n",
            "Epoch 15/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.3357 - accuracy: 0.9146\n",
            "Epoch 16/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.2849 - accuracy: 0.9397\n",
            "Epoch 17/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.2838 - accuracy: 0.9497\n",
            "Epoch 18/100\n",
            "7/7 [==============================] - 0s 23ms/step - loss: 0.2889 - accuracy: 0.9347\n",
            "Epoch 19/100\n",
            "7/7 [==============================] - 0s 24ms/step - loss: 0.2899 - accuracy: 0.9347\n",
            "Epoch 20/100\n",
            "7/7 [==============================] - 0s 23ms/step - loss: 0.2789 - accuracy: 0.9347\n",
            "Epoch 21/100\n",
            "7/7 [==============================] - 0s 23ms/step - loss: 0.5023 - accuracy: 0.9045\n",
            "Epoch 22/100\n",
            "7/7 [==============================] - 0s 24ms/step - loss: 0.4537 - accuracy: 0.9045\n",
            "Epoch 23/100\n",
            "7/7 [==============================] - 0s 25ms/step - loss: 0.3655 - accuracy: 0.9246\n",
            "Epoch 24/100\n",
            "7/7 [==============================] - 0s 23ms/step - loss: 0.2730 - accuracy: 0.9347\n",
            "Epoch 25/100\n",
            "7/7 [==============================] - 0s 23ms/step - loss: 0.3133 - accuracy: 0.9397\n",
            "Epoch 26/100\n",
            "7/7 [==============================] - 0s 25ms/step - loss: 0.3402 - accuracy: 0.9548\n",
            "Epoch 27/100\n",
            "7/7 [==============================] - 0s 24ms/step - loss: 0.1985 - accuracy: 0.9648\n",
            "Epoch 28/100\n",
            "7/7 [==============================] - 0s 23ms/step - loss: 0.1703 - accuracy: 0.9497\n",
            "Epoch 29/100\n",
            "7/7 [==============================] - 0s 25ms/step - loss: 0.1977 - accuracy: 0.9698\n",
            "Epoch 30/100\n",
            "7/7 [==============================] - 0s 23ms/step - loss: 0.1665 - accuracy: 0.9749\n",
            "Epoch 31/100\n",
            "7/7 [==============================] - 0s 24ms/step - loss: 0.1178 - accuracy: 0.9899\n",
            "Epoch 32/100\n",
            "7/7 [==============================] - 0s 23ms/step - loss: 0.1033 - accuracy: 0.9749\n",
            "Epoch 33/100\n",
            "7/7 [==============================] - 0s 25ms/step - loss: 0.0869 - accuracy: 0.9950\n",
            "Epoch 34/100\n",
            "7/7 [==============================] - 0s 25ms/step - loss: 0.0785 - accuracy: 0.9849\n",
            "Epoch 35/100\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.1564 - accuracy: 0.9899\n",
            "Epoch 36/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.1572 - accuracy: 0.9849\n",
            "Epoch 37/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.1121 - accuracy: 0.9849\n",
            "Epoch 38/100\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.0632 - accuracy: 0.9899\n",
            "Epoch 39/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0834 - accuracy: 0.9849\n",
            "Epoch 40/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0764 - accuracy: 0.9849\n",
            "Epoch 41/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0637 - accuracy: 0.9799\n",
            "Epoch 42/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0523 - accuracy: 0.9849\n",
            "Epoch 43/100\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.0510 - accuracy: 0.9899\n",
            "Epoch 44/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0475 - accuracy: 0.9849\n",
            "Epoch 45/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.0542 - accuracy: 0.9849\n",
            "Epoch 46/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0455 - accuracy: 0.9849\n",
            "Epoch 47/100\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.0438 - accuracy: 0.9849\n",
            "Epoch 48/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0443 - accuracy: 0.9950\n",
            "Epoch 49/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0809 - accuracy: 0.9899\n",
            "Epoch 50/100\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.1763 - accuracy: 0.9749\n",
            "Epoch 51/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.1381 - accuracy: 0.9799\n",
            "Epoch 52/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.0962 - accuracy: 0.9749\n",
            "Epoch 53/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0707 - accuracy: 0.9849\n",
            "Epoch 54/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0563 - accuracy: 0.9899\n",
            "Epoch 55/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0496 - accuracy: 0.9849\n",
            "Epoch 56/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.1035 - accuracy: 0.9749\n",
            "Epoch 57/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0840 - accuracy: 0.9849\n",
            "Epoch 58/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0637 - accuracy: 0.9799\n",
            "Epoch 59/100\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.0555 - accuracy: 0.9849\n",
            "Epoch 60/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0829 - accuracy: 0.9799\n",
            "Epoch 61/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0630 - accuracy: 0.9849\n",
            "Epoch 62/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0792 - accuracy: 0.9849\n",
            "Epoch 63/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.2160 - accuracy: 0.9598\n",
            "Epoch 64/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.2216 - accuracy: 0.9598\n",
            "Epoch 65/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.1653 - accuracy: 0.9698\n",
            "Epoch 66/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0730 - accuracy: 0.9849\n",
            "Epoch 67/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0628 - accuracy: 0.9849\n",
            "Epoch 68/100\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.0513 - accuracy: 0.9899\n",
            "Epoch 69/100\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.0416 - accuracy: 0.9899\n",
            "Epoch 70/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0558 - accuracy: 0.9799\n",
            "Epoch 71/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0553 - accuracy: 0.9849\n",
            "Epoch 72/100\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.0493 - accuracy: 0.9799\n",
            "Epoch 73/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0311 - accuracy: 0.9950\n",
            "Epoch 74/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0277 - accuracy: 0.9950\n",
            "Epoch 75/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0276 - accuracy: 0.9950\n",
            "Epoch 76/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0223 - accuracy: 0.9899\n",
            "Epoch 77/100\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.0246 - accuracy: 0.9899\n",
            "Epoch 78/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0204 - accuracy: 0.9950\n",
            "Epoch 79/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.0209 - accuracy: 0.9950\n",
            "Epoch 80/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.0199 - accuracy: 0.9950\n",
            "Epoch 81/100\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.0202 - accuracy: 0.9950\n",
            "Epoch 82/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0184 - accuracy: 0.9950\n",
            "Epoch 83/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0226 - accuracy: 0.9950\n",
            "Epoch 84/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0229 - accuracy: 0.9950\n",
            "Epoch 85/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0398 - accuracy: 0.9950\n",
            "Epoch 86/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0371 - accuracy: 0.9950\n",
            "Epoch 87/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0235 - accuracy: 0.9950\n",
            "Epoch 88/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0185 - accuracy: 0.9950\n",
            "Epoch 89/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0212 - accuracy: 0.9950\n",
            "Epoch 90/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0212 - accuracy: 0.9950\n",
            "Epoch 91/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0183 - accuracy: 0.9950\n",
            "Epoch 92/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0195 - accuracy: 0.9899\n",
            "Epoch 93/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0163 - accuracy: 0.9899\n",
            "Epoch 94/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0199 - accuracy: 0.9849\n",
            "Epoch 95/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0337 - accuracy: 0.9899\n",
            "Epoch 96/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.0701 - accuracy: 0.9899\n",
            "Epoch 97/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0366 - accuracy: 0.9899\n",
            "Epoch 98/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0383 - accuracy: 0.9950\n",
            "Epoch 99/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0351 - accuracy: 0.9899\n",
            "Epoch 100/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0222 - accuracy: 0.9950\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def buildPhrase(inp_str, str_len = 50):\n",
        "  for i in range(str_len):\n",
        "    x = []\n",
        "    for j in range(i, i+inp_chars):\n",
        "      x.append(tokenizer.texts_to_matrix(inp_str[j])) # преобразуем символы в One-Hot-encoding\n",
        "\n",
        "    x = np.array(x)\n",
        "    inp = x.reshape(1, inp_chars, num_characters)\n",
        "\n",
        "    pred = model.predict( inp ) # предсказываем OHE четвертого символа\n",
        "    d = tokenizer.index_word[pred.argmax(axis=1)[0]] # получаем ответ в символьном представлении\n",
        "\n",
        "    inp_str += d # дописываем строку\n",
        "\n",
        "  return inp_str"
      ],
      "metadata": {
        "id": "s0_LNL2pMiku"
      },
      "execution_count": 378,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = buildPhrase(\"утренн\")\n",
        "print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-vxdO-dMijp",
        "outputId": "6b7105f2-c4cc-4e28-b522-cde708f549f2"
      },
      "execution_count": 379,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 150ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "утренновтовн  и верьте в свою способность достигать отли\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Слова\n"
      ],
      "metadata": {
        "id": "5Lp6XvkoOYyH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('train_data.txt', 'r', encoding='utf-8') as f:\n",
        "    texts2 = f.read()\n",
        "    texts2 = texts2.replace('\\ufeff', '') # убираем первый невидимый символ"
      ],
      "metadata": {
        "id": "_-Wq8QJ2PDM2"
      },
      "execution_count": 409,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "maxWordsCount2 = 1000\n",
        "tokenizer = Tokenizer(num_words=maxWordsCount, filters='!–\"—#$%&amp;()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n\\r«»',\n",
        "                       lower=True, split=' ', char_level=False)\n",
        "tokenizer.fit_on_texts([texts2])"
      ],
      "metadata": {
        "id": "revghpcNPQSd"
      },
      "execution_count": 410,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dist = list(tokenizer.word_counts.items())\n",
        "print(dist[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPga89Z4PVFe",
        "outputId": "d424d3af-8e56-408f-f534-937612467bcc"
      },
      "execution_count": 411,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('вы', 3), ('лучший', 1), ('ответ', 1), ('на', 1), ('проблемы', 1), ('которые', 1), ('возникли', 1), ('в', 3), ('понедельник', 2), ('думайте', 1)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = tokenizer.texts_to_sequences([texts2])\n",
        "\n",
        "print(data)"
      ],
      "metadata": {
        "id": "7mpCwwYQP5hV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1459daf-1198-425f-fa1b-24f000902019"
      },
      "execution_count": 412,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1, 4, 5, 6, 7, 8, 9, 2, 3, 10, 11, 12, 13, 2, 14, 15, 16, 17, 18, 19, 1, 20, 2, 3, 21, 22, 23, 24, 1, 25, 26]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# data"
      ],
      "metadata": {
        "id": "tPDrhzF4P7Lk"
      },
      "execution_count": 413,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(data[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fA6DuYkoQS8N",
        "outputId": "7b84df3b-42a9-4d97-ccde-3df1232536cb"
      },
      "execution_count": 414,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "31"
            ]
          },
          "metadata": {},
          "execution_count": 414
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res = keras.utils.to_categorical(data[0], num_classes=maxWordsCount)\n",
        "print( res.shape )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILtfEKKIQH2d",
        "outputId": "a27fbc0c-a9a5-430d-bf72-f33b79f611f1"
      },
      "execution_count": 415,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(31, 1000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inp_words2 = 3\n",
        "n = res.shape[0]-inp_words"
      ],
      "metadata": {
        "id": "pVSmTo2qQyer"
      },
      "execution_count": 416,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array([res[i:i+inp_words, :] for i in range(n)])\n",
        "Y = res[inp_words:]"
      ],
      "metadata": {
        "id": "_ljnZUqXQ3Zz"
      },
      "execution_count": 417,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://github.com/allseenn/neuronet/blob/f3049edbe81f67d46557b8078fa603a73d667a6f/05.Tasks/hw05neuro.ipynb#L22\n",
        "\n",
        "# model = Sequential()\n",
        "# model.add(Input((inp_words, maxWordsCount)))\n",
        "# model.add(SimpleRNN(128, activation='tanh'))\n",
        "# model.add(Dense(maxWordsCount, activation='softmax'))\n",
        "# model.summary()\n",
        "\n",
        "# model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
        "\n",
        "\n",
        "from tensorflow.keras.layers import Dropout\n",
        "\n",
        "model2 = Sequential()\n",
        "model2.add(Input((inp_words2, maxWordsCount2)))\n",
        "model2.add(SimpleRNN(256, activation='tanh', return_sequences=True))\n",
        "model2.add(Dropout(0.2))  # Добавляем dropout для уменьшения переобучения\n",
        "model2.add(SimpleRNN(256, activation='tanh'))\n",
        "model2.add(Dropout(0.2))  # Добавляем dropout для уменьшения переобучения\n",
        "model2.add(Dense(maxWordsCount2, activation='softmax'))\n",
        "model2.summary()\n",
        "model2.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yc8dLHkSQ9Nr",
        "outputId": "67558890-102d-4f58-ae3b-e8f87bcb876c"
      },
      "execution_count": 418,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_19\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " simple_rnn_17 (SimpleRNN)   (None, 3, 256)            321792    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 3, 256)            0         \n",
            "                                                                 \n",
            " simple_rnn_18 (SimpleRNN)   (None, 256)               131328    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 1000)              257000    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 710120 (2.71 MB)\n",
            "Trainable params: 710120 (2.71 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model2.fit(X, Y, batch_size=32, epochs=59)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Av36xtecRA8L",
        "outputId": "5d846180-a336-48d2-e0a9-31c8ba2e6265"
      },
      "execution_count": 419,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/59\n",
            "1/1 [==============================] - 2s 2s/step - loss: 6.9144 - accuracy: 0.0000e+00\n",
            "Epoch 2/59\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 6.7738 - accuracy: 0.1071\n",
            "Epoch 3/59\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 6.6682 - accuracy: 0.3929\n",
            "Epoch 4/59\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 6.5296 - accuracy: 0.8214\n",
            "Epoch 5/59\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 6.3980 - accuracy: 1.0000\n",
            "Epoch 6/59\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 6.2213 - accuracy: 1.0000\n",
            "Epoch 7/59\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 6.0766 - accuracy: 1.0000\n",
            "Epoch 8/59\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 5.9103 - accuracy: 1.0000\n",
            "Epoch 9/59\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 5.6876 - accuracy: 0.9643\n",
            "Epoch 10/59\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 5.4466 - accuracy: 0.9643\n",
            "Epoch 11/59\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 5.2104 - accuracy: 0.9643\n",
            "Epoch 12/59\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 4.8769 - accuracy: 0.9643\n",
            "Epoch 13/59\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 4.4830 - accuracy: 0.9643\n",
            "Epoch 14/59\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 4.1201 - accuracy: 0.9286\n",
            "Epoch 15/59\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 3.6419 - accuracy: 0.8571\n",
            "Epoch 16/59\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 3.1251 - accuracy: 0.8571\n",
            "Epoch 17/59\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.7834 - accuracy: 0.7500\n",
            "Epoch 18/59\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 2.4556 - accuracy: 0.6429\n",
            "Epoch 19/59\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.1685 - accuracy: 0.6429\n",
            "Epoch 20/59\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.0339 - accuracy: 0.5714\n",
            "Epoch 21/59\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 1.9417 - accuracy: 0.5357\n",
            "Epoch 22/59\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.7491 - accuracy: 0.6429\n",
            "Epoch 23/59\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 1.6402 - accuracy: 0.6429\n",
            "Epoch 24/59\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 1.4240 - accuracy: 0.8571\n",
            "Epoch 25/59\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 1.2139 - accuracy: 0.9286\n",
            "Epoch 26/59\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.9768 - accuracy: 1.0000\n",
            "Epoch 27/59\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.8253 - accuracy: 0.9643\n",
            "Epoch 28/59\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.7090 - accuracy: 0.9286\n",
            "Epoch 29/59\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.6568 - accuracy: 0.8571\n",
            "Epoch 30/59\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5338 - accuracy: 0.9286\n",
            "Epoch 31/59\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.4596 - accuracy: 0.9286\n",
            "Epoch 32/59\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.4154 - accuracy: 1.0000\n",
            "Epoch 33/59\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.3826 - accuracy: 0.9643\n",
            "Epoch 34/59\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.3263 - accuracy: 1.0000\n",
            "Epoch 35/59\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.2820 - accuracy: 0.9643\n",
            "Epoch 36/59\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.2762 - accuracy: 0.9643\n",
            "Epoch 37/59\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.2564 - accuracy: 0.9643\n",
            "Epoch 38/59\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.2206 - accuracy: 0.9643\n",
            "Epoch 39/59\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.2104 - accuracy: 0.9643\n",
            "Epoch 40/59\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.1969 - accuracy: 0.9643\n",
            "Epoch 41/59\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.1748 - accuracy: 1.0000\n",
            "Epoch 42/59\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.1596 - accuracy: 1.0000\n",
            "Epoch 43/59\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.1323 - accuracy: 1.0000\n",
            "Epoch 44/59\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.1184 - accuracy: 1.0000\n",
            "Epoch 45/59\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.1296 - accuracy: 1.0000\n",
            "Epoch 46/59\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.1393 - accuracy: 0.9643\n",
            "Epoch 47/59\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.1043 - accuracy: 1.0000\n",
            "Epoch 48/59\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.1227 - accuracy: 0.9643\n",
            "Epoch 49/59\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0911 - accuracy: 1.0000\n",
            "Epoch 50/59\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0935 - accuracy: 1.0000\n",
            "Epoch 51/59\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0850 - accuracy: 1.0000\n",
            "Epoch 52/59\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0806 - accuracy: 1.0000\n",
            "Epoch 53/59\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0782 - accuracy: 1.0000\n",
            "Epoch 54/59\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0801 - accuracy: 0.9643\n",
            "Epoch 55/59\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0739 - accuracy: 1.0000\n",
            "Epoch 56/59\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0663 - accuracy: 1.0000\n",
            "Epoch 57/59\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0618 - accuracy: 1.0000\n",
            "Epoch 58/59\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0628 - accuracy: 1.0000\n",
            "Epoch 59/59\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0741 - accuracy: 0.9643\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def buildPhrase2(texts : str, str_len = 20):\n",
        "  res = texts\n",
        "  dataa = tokenizer.texts_to_sequences([texts])[0]\n",
        "  for i in range(str_len):\n",
        "    x = keras.utils.to_categorical(dataa[i: i+inp_words], num_classes=maxWordsCount) # преобразуем в One-Hot-encoding\n",
        "    inp = x.reshape(1, inp_words, maxWordsCount)\n",
        "    pred = model.predict( inp ) # предсказываем OHE четвертого символа\n",
        "    indx = pred.argmax(axis=1)[0]\n",
        "    data.append(indx)\n",
        "    res += \" \" + tokenizer.index_word[indx] # дописываем строку\n",
        "  return res"
      ],
      "metadata": {
        "id": "WiPb0RnqRJiT"
      },
      "execution_count": 420,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1):\n",
        "    x = keras.utils.to_categorical(data[i: i+inp_words], num_classes=maxWordsCount)"
      ],
      "metadata": {
        "id": "yrBbGq92UeSP"
      },
      "execution_count": 422,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9CEjebYVUpuH",
        "outputId": "75495eee-3f30-4cbd-b6e2-74f278eba572"
      },
      "execution_count": 423,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 31, 1000)"
            ]
          },
          "metadata": {},
          "execution_count": 423
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# res = buildPhrase2(\"позитив добавляет годы\")\n",
        "# print(res)\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# ValueError                                Traceback (most recent call last)\n",
        "# <ipython-input-319-c4bf87fabd6e> in <cell line: 1>()\n",
        "# ----> 1 res = buildPhrase2(\"позитив добавляет годы\")\n",
        "#       2 print(res)\n",
        "\n",
        "# <ipython-input-316-b7a752cdecfb> in buildPhrase2(texts, str_len)\n",
        "#       4   for i in range(str_len):\n",
        "#       5     x = keras.utils.to_categorical(dataa[i: i+inp_words], num_classes=maxWordsCount) # преобразуем в One-Hot-encoding\n",
        "# ----> 6     inp = x.reshape(1, inp_words, maxWordsCount)\n",
        "#       7     pred = model.predict( inp ) # предсказываем OHE четвертого символа\n",
        "#       8     indx = pred.argmax(axis=1)[0]\n",
        "\n",
        "# ValueError: cannot reshape array of size 0 into shape (1,3,1000)\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# ValueError                                Traceback (most recent call last)\n",
        "# <ipython-input-424-ebad082d41fe> in <cell line: 1>()\n",
        "# ----> 1 res = buildPhrase2(\"позитив добавляет годы\")\n",
        "#       2 print(res)\n",
        "#       3\n",
        "#       4\n",
        "#       5 # ---------------------------------------------------------------------------\n",
        "\n",
        "# <ipython-input-420-b7a752cdecfb> in buildPhrase2(texts, str_len)\n",
        "#       4   for i in range(str_len):\n",
        "#       5     x = keras.utils.to_categorical(dataa[i: i+inp_words], num_classes=maxWordsCount) # преобразуем в One-Hot-encoding\n",
        "# ----> 6     inp = x.reshape(1, inp_words, maxWordsCount)\n",
        "#       7     pred = model.predict( inp ) # предсказываем OHE четвертого символа\n",
        "#       8     indx = pred.argmax(axis=1)[0]\n",
        "\n",
        "# ValueError: cannot reshape array of size 0 into shape (1,3,1000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "v2L7ReIFRUuz",
        "outputId": "cff763dd-ba2f-439d-b4d8-6399999150e6"
      },
      "execution_count": 424,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "cannot reshape array of size 0 into shape (1,3,1000)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-424-ebad082d41fe>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuildPhrase2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"позитив добавляет годы\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# ---------------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-420-b7a752cdecfb>\u001b[0m in \u001b[0;36mbuildPhrase2\u001b[0;34m(texts, str_len)\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataa\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0minp_words\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaxWordsCount\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# преобразуем в One-Hot-encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxWordsCount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0minp\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;31m# предсказываем OHE четвертого символа\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mindx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 0 into shape (1,3,1000)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texts = \"позитив добавляет годы\"\n",
        "res = texts\n",
        "dataa = tokenizer.texts_to_sequences([texts])[0]\n",
        "for i in range(str_len):\n",
        "  x = keras.utils.to_categorical(dataa[i: i+inp_words], num_classes=maxWordsCount) # преобразуем в One-Hot-encoding\n",
        "  inp = x.reshape(1, inp_words, maxWordsCount)\n",
        "  pred = model.predict( inp ) # предсказываем OHE четвертого символа\n",
        "  indx = pred.argmax(axis=1)[0]\n",
        "  data.append(indx)\n",
        "  res += \" \" + tokenizer.index_word[indx] # дописываем строку\n",
        "print(res)\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# ValueError                                Traceback (most recent call last)\n",
        "# <ipython-input-396-799b6d235b47> in <cell line: 4>()\n",
        "#       4 for i in range(str_len):\n",
        "#       5   x = keras.utils.to_categorical(dataa[i: i+inp_words], num_classes=maxWordsCount) # преобразуем в One-Hot-encoding\n",
        "# ----> 6   inp = x.reshape(1, inp_words, maxWordsCount)\n",
        "#       7   pred = model.predict( inp ) # предсказываем OHE четвертого символа\n",
        "#       8   indx = pred.argmax(axis=1)[0]\n",
        "\n",
        "# ValueError: cannot reshape array of size 0 into shape (1,3,1000)\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# ValueError                                Traceback (most recent call last)\n",
        "# <ipython-input-425-8e1eb0d2da86> in <cell line: 4>()\n",
        "#       4 for i in range(str_len):\n",
        "#       5   x = keras.utils.to_categorical(dataa[i: i+inp_words], num_classes=maxWordsCount) # преобразуем в One-Hot-encoding\n",
        "# ----> 6   inp = x.reshape(1, inp_words, maxWordsCount)\n",
        "#       7   pred = model.predict( inp ) # предсказываем OHE четвертого символа\n",
        "#       8   indx = pred.argmax(axis=1)[0]\n",
        "\n",
        "# ValueError: cannot reshape array of size 0 into shape (1,3,1000)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "RS-p3KeLUPnL",
        "outputId": "ee7af1a6-4894-494c-9c40-04d928f35da5"
      },
      "execution_count": 425,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "cannot reshape array of size 0 into shape (1,3,1000)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-425-8e1eb0d2da86>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataa\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0minp_words\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaxWordsCount\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# преобразуем в One-Hot-encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxWordsCount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m   \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0minp\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;31m# предсказываем OHE четвертого символа\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mindx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 0 into shape (1,3,1000)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "35eqs0oAVSl0"
      }
    }
  ]
}